{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Cluster Family Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running BiG-SCAPE in a notebook in order to understand how it works .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "from array import array\n",
    "\n",
    "sys.path.append('/Users/joewandy/git/BiG-SCAPE/')\n",
    "sys.path.append('/Users/joewandy/anaconda/envs/bigscape/lib/python2.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bigscape as bs\n",
    "import functions as f\n",
    "import ArrowerSVG as arr\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predicting domains using hmmscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_folder = '/Users/joewandy/Dropbox/Meta_clustering/MS2LDA/BGC/data/bgcsforJustin/output'\n",
    "f.create_directory(output_folder, \"Output\", False)\n",
    "bgc_fasta_folder = os.path.join(output_folder, \"fasta\")\n",
    "f.create_directory(bgc_fasta_folder, \"BGC fastas\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class bgc_data:\n",
    "    def __init__(self, accession_id, description, product, records, max_width, organism, taxonomy, biosynthetic_genes,\n",
    "                 contig_edge):\n",
    "        # These two properties come from the genbank file:\n",
    "        self.accession_id = accession_id\n",
    "        self.description = description\n",
    "        # AntiSMASH predicted class of compound:\n",
    "        self.product = product\n",
    "        # number of records in the genbank file (think of multi-locus BGCs):\n",
    "        self.records = records\n",
    "        # length of largest record (it will be used for ArrowerSVG):\n",
    "        self.max_width = int(max_width)\n",
    "        # organism\n",
    "        self.organism = organism\n",
    "        # taxonomy as a string (of comma-separated values)\n",
    "        self.taxonomy = taxonomy\n",
    "        # Internal set of tags corresponding to genes that AntiSMASH marked\n",
    "        # as \"Kind: Biosynthetic\". It is formed as\n",
    "        # clusterName + \"_ORF\" + cds_number + \":gid:\" + gene_id + \":pid:\" + protein_id + \":loc:\" + gene_start + \":\" + gene_end + \":strand:\" + {+,-}\n",
    "        self.biosynthetic_genes = biosynthetic_genes\n",
    "        # AntiSMASH 4+ marks BGCs that sit on the edge of a contig\n",
    "        self.contig_edge = contig_edge\n",
    "        \n",
    "bs.bgc_data = bgc_data\n",
    "bs.mode = 'global'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputdir = '/Users/joewandy/Dropbox/Meta_clustering/MS2LDA/BGC/data/bgcsforJustin/'\n",
    "bgc_info = {} # Stores, per BGC: predicted type, gbk Description, \n",
    "              # number of records, width of longest record, \n",
    "              # GenBank's accession, Biosynthetic Genes' ids\n",
    "\n",
    "min_bgc_size = 0 # Provide the minimum size of a BGC to be included in the analysis. Default is 0 base pairs\n",
    "exclude_gbk_str = '' # If this string occurs in the gbk filename, this file will not be used for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# genbankDict: {cluster_name:[genbank_path_to_1st_instance,[sample_1,sample_2,...]]}\n",
    "genbankDict = bs.get_gbk_files(inputdir, output_folder, bgc_fasta_folder, \n",
    "                            min_bgc_size, exclude_gbk_str, bgc_info)\n",
    "\n",
    "# clusters and sampleDict contain the necessary structure for all-vs-all and sample analysis\n",
    "clusters = genbankDict.keys()\n",
    "clusterNames = tuple(sorted(clusters))\n",
    "    \n",
    "sampleDict = {} # {sampleName:set(bgc1,bgc2,...)}\n",
    "gbk_files = [] # raw list of gbk file locations\n",
    "for (cluster, (path, clusterSample)) in genbankDict.items():\n",
    "    gbk_files.append(path)\n",
    "    for sample in clusterSample:\n",
    "        clustersInSample = sampleDict.get(sample, set())\n",
    "        clustersInSample.add(cluster)\n",
    "        sampleDict[sample] = clustersInSample\n",
    "        \n",
    "baseNames = set(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allFastaFiles = set(glob(os.path.join(bgc_fasta_folder,\"*.fasta\")))\n",
    "fastaFiles = set()\n",
    "for name in baseNames:\n",
    "    fastaFiles.add(os.path.join(bgc_fasta_folder, name+\".fasta\"))    \n",
    "fastaBases = allFastaFiles.intersection(fastaFiles)\n",
    "task_set = fastaFiles\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domtable_folder = os.path.join(output_folder, \"domtable\")\n",
    "f.create_directory(domtable_folder, \"Domtable\", False)\n",
    "\n",
    "pfam_dir = '/Users/joewandy/Downloads/pfam/'\n",
    "# bs.pfam_dir = pfam_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for fastaFile in task_set:\n",
    "    print 'Processing %d/%d' % (i, len(task_set))\n",
    "    bs.runHmmScan(fastaFile, pfam_dir, domtable_folder, verbose)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Parse hmmscan domtable results and generate pfs and pfd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pfs_folder = os.path.join(output_folder, \"pfs\")\n",
    "pfd_folder = os.path.join(output_folder, \"pfd\")    \n",
    "f.create_directory(pfs_folder, \"pfs\", False)\n",
    "f.create_directory(pfd_folder, \"pfd\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allDomtableFiles = set(glob(os.path.join(domtable_folder,\"*.domtable\")))\n",
    "domtableFiles = set()\n",
    "for name in baseNames:\n",
    "    domtableFiles.add(os.path.join(domtable_folder, name+\".domtable\"))\n",
    "domtableBases = allDomtableFiles.intersection(domtableFiles)\n",
    "alreadyDone = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs.gbk_files = gbk_files\n",
    "bs.genbankDict = genbankDict\n",
    "bs.clusters = clusters\n",
    "bs.baseNames = baseNames\n",
    "bs.sampleDict = sampleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify at which overlap percentage domains are considered to overlap. \n",
    "# Domain with the best score is kept (default=0.1).\n",
    "domain_overlap_cutoff = 0.1\n",
    "for domtableFile in domtableFiles - alreadyDone:\n",
    "    try:\n",
    "        bs.parseHmmScan(domtableFile, pfd_folder, pfs_folder, domain_overlap_cutoff)\n",
    "    except IndexError:\n",
    "        continue\n",
    "    except ValueError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Parse the pfs, pfd files to generate BGC dictionary, clusters, and clusters per sample objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing domain sequences files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allPfdFiles = set(glob(os.path.join(pfd_folder,\"*.pfd\")))\n",
    "# pfdFiles = set()\n",
    "# for name in baseNames:\n",
    "#     pfdFiles.add(os.path.join(pfd_folder, name+\".pfd\"))\n",
    "# pfdBases = allPfdFiles.intersection(pfdFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create SVG figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "availableSVGs = set()\n",
    "for svg in glob(os.path.join(svg_folder,\"*.svg\")):\n",
    "    (root, ext) = os.path.splitext(svg)\n",
    "    availableSVGs.add(root.split(os.sep)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_set = availableSVGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_genes = arr.read_color_genes_file()\n",
    "color_domains = arr.read_color_domains_file()\n",
    "pfam_domain_categories = arr.read_pfam_domain_categories()\n",
    "\n",
    "print(\"  Parsing hmm file for domain names\")\n",
    "pfam_info = {}\n",
    "with open(os.path.join(pfam_dir, \"Pfam-A.hmm\"), \"r\") as pfam:\n",
    "    putindict = False\n",
    "    # assuming that the order of the information never changes\n",
    "    for line in pfam:\n",
    "        if line[:4] == \"NAME\":\n",
    "            name = line.strip()[6:]\n",
    "        if line[:3] == \"ACC\":\n",
    "            acc = line.strip()[6:].split(\".\")[0]\n",
    "        if line[:4] == \"DESC\":\n",
    "            desc = line.strip()[6:]\n",
    "            putindict = True\n",
    "\n",
    "        if putindict:\n",
    "            putindict = False\n",
    "            pfam_info[acc] = (name, desc)\n",
    "print(\"    Done\")\n",
    "\n",
    "#This must be done serially, because if a color for a gene/domain\n",
    "# is not found, the text files with colors need to be updated\n",
    "print(\"  Reading BGC information and writing SVG\")\n",
    "for bgc in working_set:\n",
    "    arr.SVG(False, os.path.join(svg_folder,bgc+\".svg\"), genbankDict[bgc][0], os.path.join(pfd_folder,bgc+\".pfd\"), True, color_genes, color_domains, pfam_domain_categories, pfam_info, bgc_info[bgc].records, bgc_info[bgc].max_width)\n",
    "\n",
    "color_genes.clear()\n",
    "color_domains.clear()\n",
    "pfam_domain_categories.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculating distance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing multiple alignment of domain sequences. First, Obtain all fasta files with domain sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fasta_domains = set(glob(os.path.join(domains_folder,\"*.fasta\")))\n",
    "print list(fasta_domains)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to further reduce the set of domain fastas that need alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fasta_domains_temp = fasta_domains.copy()\n",
    "for domain_file in fasta_domains_temp:\n",
    "    \n",
    "    domain_name = \".\".join(domain_file.split(os.sep)[-1].split(\".\")[:-1])\n",
    "\n",
    "    # fill fasta_dict...\n",
    "    with open(domain_file, \"r\") as fasta_handle:\n",
    "        header_list = bs.get_fasta_keys(fasta_handle)\n",
    "\n",
    "    # Get the BGC name from the sequence tag. The form of the tag is:\n",
    "    # >BGCXXXXXXX_BGCXXXXXXX_ORF25:gid...\n",
    "    sequence_tag_list = set(s.split(\"_ORF\")[0] for s in header_list)\n",
    "\n",
    "    # ...to find out how many sequences do we actually have\n",
    "    if len(sequence_tag_list) == 1:\n",
    "        \n",
    "        # avoid multiple alignment if the domains all belong to the same BGC\n",
    "        fasta_domains.remove(domain_file)\n",
    "        print(\"Skipping Multiple Alignment for {} (appears only in one BGC)\".format(domain_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs.pfam_dir = pfam_dir\n",
    "i = 0\n",
    "for domain in fasta_domains:\n",
    "    print '%d/%d: %s' % (i, len(fasta_domains), domain)\n",
    "    bs.run_hmmalign(domain)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Generating distance network files with ALL available input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "networks_folder_all = \"networks_all_hybrids\"\n",
    "bs.create_directory(os.path.join(output_folder, networks_folder_all), \"Networks_all\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bgc_class_weight = {}\n",
    "bgc_class_weight[\"PKSI\"] = (0.22, 0.76, 0.02, 1.0)\n",
    "bgc_class_weight[\"PKSother\"] = (0.0, 0.32, 0.68, 4.0)\n",
    "bgc_class_weight[\"NRPS\"] = (0.0, 1.0, 0.0, 4.0)\n",
    "bgc_class_weight[\"RiPPs\"] = (0.28, 0.71, 0.01, 1.0)\n",
    "bgc_class_weight[\"Saccharides\"] = (0.0, 0.0, 1.0, 1.0)\n",
    "bgc_class_weight[\"Terpene\"] = (0.2, 0.75, 0.05, 2.0)\n",
    "bgc_class_weight[\"PKS-NRP_Hybrids\"] = (0.0, 0.78, 0.22, 1.0)\n",
    "bgc_class_weight[\"Others\"] = (0.01, 0.97, 0.02, 4.0)\n",
    "\n",
    "valid_classes = set()\n",
    "for key in bgc_class_weight:\n",
    "    valid_classes.add(key.lower())\n",
    "\n",
    "bgc_class_weight[\"mix\"] = (0.2, 0.75, 0.05, 2.0) # default when not separating in classes\n",
    "\n",
    "BGC_classes = defaultdict(list)\n",
    "# mix class will always be the last element of the tuple\n",
    "bgcClassNames = tuple(sorted(list(bgc_class_weight)) + [\"mix\"])\n",
    "assert bgcClassNames[-1] == 'mix'\n",
    "\n",
    "bgcClassName2idx = dict(zip(bgcClassNames,range(len(bgcClassNames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BGC_classes = defaultdict(list)\n",
    "# bs.valid_classes = valid_classes\n",
    "\n",
    "for clusterIdx,clusterName in enumerate(clusterNames):\n",
    "    \n",
    "    product = bgc_info[clusterName].product\n",
    "    predicted_class = f.sort_bgc(product)\n",
    "    if predicted_class.lower() in valid_classes:\n",
    "        BGC_classes[predicted_class].append(clusterIdx)\n",
    "        \n",
    "    if predicted_class == \"PKS-NRP_Hybrids\":\n",
    "        if \"nrps\" in valid_classes:\n",
    "            BGC_classes[\"NRPS\"].append(clusterIdx)\n",
    "        if \"t1pks\" in product and \"pksi\" in valid_classes:\n",
    "            BGC_classes[\"PKSI\"].append(clusterIdx)\n",
    "        if \"t1pks\" not in product and \"pksother\" in valid_classes:\n",
    "            BGC_classes[\"PKSother\"].append(clusterIdx)\n",
    "\n",
    "    if predicted_class == \"Others\" and \"-\" in product:\n",
    "        subclasses = set()\n",
    "        for subproduct in product.split(\"-\"):\n",
    "            subclass = bs.sort_bgc(subproduct)\n",
    "            if subclass.lower() in valid_classes:\n",
    "                subclasses.add(subclass)\n",
    "                \n",
    "        # Prevent mixed BGCs with sub-Others annotations to get\n",
    "        # added twice (e.g. indole-cf_fatty_acid has already gone\n",
    "        # to Others at this point)\n",
    "        if \"Others\" in subclasses:\n",
    "            subclasses.remove(\"Others\")\n",
    "\n",
    "        for subclass in subclasses:\n",
    "            BGC_classes[subclass].append(clusterIdx)\n",
    "        subclasses.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cores = cpu_count()\n",
    "bs.clusterNames = clusterNames\n",
    "bs.bgcClassNames = bgcClassNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Key: BGC. Item: ordered list of simple integers with the number of domains\n",
    "# in each gene\n",
    "# Instead of `DomainCountGene = defaultdict(list)`, let's try arrays of \n",
    "# unsigned ints\n",
    "DomainCountGene = {}\n",
    "# list of gene-numbers that have a hit in the anchor domain list. Zero based\n",
    "corebiosynthetic_position = {}\n",
    "# list of +/- orientation \n",
    "BGCGeneOrientation = {}\n",
    "\n",
    "# if it's a re-run, the pfd/pfs files were not changed, so the skip_ma flag\n",
    "# is activated. We have to open the pfd files to get the gene labels for\n",
    "# each domain\n",
    "# We now always have to have this data so the alignments are produced\n",
    "for outputbase in baseNames:\n",
    "    DomainCountGene[outputbase] = array('B')\n",
    "    corebiosynthetic_position[outputbase] = array('B')\n",
    "    BGCGeneOrientation[outputbase] = array('b')\n",
    "    pfdFile = os.path.join(pfd_folder, outputbase + \".pfd\")\n",
    "    filtered_matrix = [map(lambda x: x.strip(), line.split('\\t')) for line in open(pfdFile)]\n",
    "\n",
    "    domain_counter = 0\n",
    "    gene_number = 0\n",
    "    gene_label = filtered_matrix[0][-1] # initialize with first label\n",
    "    has_corebio = False\n",
    "    for row in filtered_matrix:\n",
    "        if row[-1] != gene_label:\n",
    "            # we changed to a new gene. Check whether previous has a \n",
    "            # core biosynthetic / anchor domain hit\n",
    "            if has_corebio:\n",
    "                corebiosynthetic_position[outputbase].append(gene_number)\n",
    "                has_corebio = False\n",
    "\n",
    "            if gene_label[-1] == \"+\":\n",
    "                BGCGeneOrientation[outputbase].append(1)\n",
    "            else:\n",
    "                BGCGeneOrientation[outputbase].append(-1)\n",
    "\n",
    "            gene_label = row[-1] # update current label\n",
    "            gene_number += 1 # advance gene number\n",
    "\n",
    "            # record number of domains in previous gene\n",
    "            DomainCountGene[outputbase].append(domain_counter)\n",
    "            domain_counter = 1 # reset domain counter\n",
    "        else:\n",
    "            domain_counter += 1 # increase domain counter\n",
    "\n",
    "        # TODO: if len(corebiosynthetic_position[outputbase]) == 0\n",
    "        # do something with the list of pfam ids. Specifically, mark\n",
    "        # (in this case TODO or always?) as biosynthetic genes, the ones that contain\n",
    "        # domains from a special list. This list of special domains\n",
    "        # comes from predicted domains within the CDSs marked as 'sec_met'\n",
    "        # by antismash\n",
    "        if row[-1] in bgc_info[outputbase].biosynthetic_genes:\n",
    "            has_corebio = True\n",
    "\n",
    "    # There is no transition when we finish, so analyze last gene\n",
    "    if gene_label[-1] == \"+\":\n",
    "        BGCGeneOrientation[outputbase].append(1)\n",
    "    else:\n",
    "        BGCGeneOrientation[outputbase].append(-1)\n",
    "    DomainCountGene[outputbase].append(domain_counter)\n",
    "    if has_corebio:\n",
    "        corebiosynthetic_position[outputbase].append(gene_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domains_folder = os.path.join(output_folder, \"domains\")\n",
    "svg_folder = os.path.join(output_folder, \"SVG\")\n",
    "f.create_directory(domains_folder, \"Domains\", False)\n",
    "f.create_directory(svg_folder, \"SVG\", False)\n",
    "\n",
    "BGCs = {} # will contain the BGCs\n",
    "for outputbase in baseNames:\n",
    "    \n",
    "    print(\"Processing: \" + outputbase)\n",
    "\n",
    "    pfdFile = os.path.join(pfd_folder, outputbase + \".pfd\")\n",
    "    filtered_matrix = [[part.strip() for part in line.split('\\t')] for line in open(pfdFile)]\n",
    "    \n",
    "    # save each domain sequence from a single BGC in its corresponding file\n",
    "    fasta_file = os.path.join(bgc_fasta_folder, outputbase + \".fasta\")\n",
    "    with open(fasta_file, \"r\") as fasta_file_handle:\n",
    "        fasta_dict = bs.fasta_parser(fasta_file_handle) # all fasta info from a BGC\n",
    "    bs.save_domain_seqs(filtered_matrix, fasta_dict, domains_folder, outputbase)\n",
    "\n",
    "    BGCs[outputbase] = f.BGC_dic_gen(filtered_matrix)\n",
    "    del filtered_matrix[:]\n",
    "\n",
    "    # store processed BGCs dictionary for future re-runs\n",
    "    with open(os.path.join(output_folder, \"BGCs.dict\"), \"wb\") as BGC_file:\n",
    "        pickle.dump(BGCs, BGC_file)\n",
    "        BGC_file.close()\n",
    "        \n",
    "bs.BGCs = BGCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchorfile = '/Users/joewandy/git/BiG-SCAPE/anchor_domains.txt'\n",
    "anchor_domains = f.get_anchor_domains(anchorfile)\n",
    "bs.anchor_domains = anchor_domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the ordered list of domains from the pfs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DomainList = {} # Key: BGC. Item: ordered list of domains\n",
    "for outputbase in baseNames:\n",
    "    pfsfile = os.path.join(pfs_folder, outputbase + \".pfs\")\n",
    "    if os.path.isfile(pfsfile):\n",
    "        DomainList[outputbase] = f.get_domain_list(pfsfile)\n",
    "    else:\n",
    "        sys.exit(\" Error: could not open \" + outputbase + \".pfs\")\n",
    "        \n",
    "bs.DomainList = DomainList\n",
    "bs.DomainCountGene = DomainCountGene\n",
    "bs.corebiosynthetic_position = corebiosynthetic_position\n",
    "bs.BGCGeneOrientation = BGCGeneOrientation\n",
    "bs.bgc_class_weight = bgc_class_weight\n",
    "bs.domains_folder = domains_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AlignedDomainSequences = {} # Key: specific domain sequence label. Item: aligned sequence\n",
    "print(\" Trying to read domain alignments (*.algn files)\")\n",
    "aligned_files_list = glob(os.path.join(domains_folder, \"*.algn\"))\n",
    "if len(aligned_files_list) == 0:\n",
    "    sys.exit(\"No aligned sequences found in the domain folder (run without the --skip_ma parameter or point to the correct output folder)\")\n",
    "for aligned_file in aligned_files_list:\n",
    "    with open(aligned_file, \"r\") as aligned_file_handle:\n",
    "        fasta_dict = f.fasta_parser(aligned_file_handle)\n",
    "        for header in fasta_dict:\n",
    "            AlignedDomainSequences[header] = fasta_dict[header]\n",
    "bs.AlignedDomainSequences = AlignedDomainSequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only make folders for the BGC_classes that are found\n",
    "for bgc_class in BGC_classes:\n",
    "    folder_name = bgc_class\n",
    "\n",
    "    print(\"\\n  {} ({} BGCs)\".format(folder_name, str(len(BGC_classes[bgc_class]))))\n",
    "\n",
    "    # create output directory   \n",
    "    f.create_directory(os.path.join(output_folder, networks_folder_all, folder_name), \"  All - \" + bgc_class, False)\n",
    "\n",
    "    # Create an additional file with the final list of all clusters in the class\n",
    "    print(\"   Writing annotation files\")\n",
    "    path_list = os.path.join(output_folder, networks_folder_all, folder_name, \"Network_Annotations_All_\" + folder_name + \".tsv\")\n",
    "    with open(path_list, \"w\") as list_file:\n",
    "        list_file.write(\"BGC\\tAccesion ID\\tDescription\\tProduct Prediction\\tBiG-SCAPE class\\tOrganism\\tTaxonomy\\n\")\n",
    "        for idx in BGC_classes[bgc_class]:\n",
    "            bgc = clusterNames[idx]\n",
    "            product = bgc_info[bgc].product\n",
    "            list_file.write(\"\\t\".join([bgc, bgc_info[bgc].accession_id, bgc_info[bgc].description, product, \n",
    "                                       f.sort_bgc(product), bgc_info[bgc].organism, bgc_info[bgc].taxonomy]) + \"\\n\")\n",
    "\n",
    "    if len(BGC_classes[bgc_class]) > 1:\n",
    "        print(\"   Calculating all pairwise distances\")\n",
    "        pairs = set([tuple(sorted(combo)) for combo in combinations(BGC_classes[bgc_class], 2)])\n",
    "        cluster_pairs = [(x, y, bgcClassName2idx[bgc_class]) for (x, y) in pairs]\n",
    "        pairs.clear()\n",
    "        network_matrix = bs.generate_network(cluster_pairs, cores)\n",
    "        del cluster_pairs[:]\n",
    "\n",
    "        print(\"   Writing output files\")\n",
    "        pathBase = os.path.join(output_folder, networks_folder_all, folder_name, \"all\" + folder_name)\n",
    "        filenames = []\n",
    "        for cutoff in cutoff_list:\n",
    "            filenames.append(\"{}_c{:.2f}.network\".format(pathBase, cutoff))\n",
    "        cutoffs_and_filenames = list(zip(cutoff_list, filenames))\n",
    "        del filenames[:]\n",
    "        f.write_network_matrix(network_matrix, cutoffs_and_filenames, include_singletons, clusterNames, bgc_info)\n",
    "\n",
    "        print(\"  Calling Gene Cluster Families\")\n",
    "        reduced_network = []\n",
    "        for row in network_matrix:\n",
    "            reduced_network.append([int(row[0]), int(row[1]), row[2]])\n",
    "        del network_matrix[:]\n",
    "\n",
    "        bs.clusterJsonBatch(BGC_classes[bgc_class], pathBase, reduced_network, cutoffs=cutoff_list,clusterClans=options.clans,clanCutoff=options.clan_cutoff)\n",
    "        del BGC_classes[bgc_class][:]\n",
    "        del reduced_network[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
